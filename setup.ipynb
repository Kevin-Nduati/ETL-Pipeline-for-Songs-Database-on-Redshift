{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Redshift Cluster using the AWS Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY = config.get('AWS', 'KEY')\n",
    "SECRET = config.get('AWS', 'SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE = config.get('DWH', 'DWH_CLUSTER_TYPE')\n",
    "DWH_NUM_NODES = config.get('DWH', 'DWH_NUM_NODES')\n",
    "DWH_NODE_TYPE = config.get('DWH', 'DWH_NODE_TYPE')\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get('DWH', 'DWH_CLUSTER_IDENTIFIER')\n",
    "DWH_DB = config.get('DWH', 'DWH_DB')\n",
    "DWH_DB_USER = config.get('DWH', 'DWH_DB_USER')\n",
    "DWH_DB_PASSWORD = config.get('DWH', 'DWH_DB_PASSWORD')\n",
    "DWH_PORT = config.get('DWH', 'DWH_PORT')\n",
    "\n",
    "DWH_IAM_ROLE_NAME = config.get('DWH', 'DWH_IAM_ROLE_NAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Clients for IAM, EC2, S3 and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource(\n",
    "    'ec2',\n",
    "    region_name = 'us-west-2',\n",
    "    aws_access_key_id = KEY,\n",
    "    aws_secret_access_key = SECRET\n",
    ")\n",
    "\n",
    "# S3\n",
    "S3 = boto3.resource(\n",
    "    's3',\n",
    "    region_name = 'us-west-2',\n",
    "    aws_access_key_id = KEY,\n",
    "    aws_secret_access_key = SECRET\n",
    ")\n",
    "\n",
    "# iam\n",
    "iam = boto3.client(\n",
    "    'iam',\n",
    "    aws_access_key_id = KEY,\n",
    "    aws_secret_access_key = SECRET,\n",
    "    region_name = 'us-west-2'\n",
    ")\n",
    "\n",
    "# redshift\n",
    "redshift = boto3.client(\n",
    "    'redshift',\n",
    "    region_name = 'us-west-2',\n",
    "    aws_access_key_id = KEY,\n",
    "    aws_secret_access_key = SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IAM role that makes Redshift able to access S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# create the role\n",
    "try:\n",
    "    print('Creating a new IAM role')\n",
    "    dwhRole = iam.create_role(\n",
    "        path = '/',\n",
    "        RoleName = DWH_IAM_ROLE_NAME,\n",
    "        Description = 'Allows Redshift clusters to call AWS services on your behalf',\n",
    "        AssumeRolePolicyDocument = json.dumps(\n",
    "            {\n",
    "                'Statement': [{'Action': 'sts:AssumeRole',\n",
    "                'Effect': 'Allow',\n",
    "                'Principal': 'Service': 'redshift.amazonaws.com'}],\n",
    "                'Version': '2012-10-17'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print('Attaching Policy')\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    RoleName = DWH_IAM_ROLE_NAME,\n",
    "    PolicyArn = \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    ")['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print('Get the IAM role ARN')\n",
    "roleArn = iam.get_role(RoleName = DWH_IAM_ROLE_NAME)['Role']['ARN']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(\n",
    "        ClusetrType = DWH_CLUSTER_TYPE,\n",
    "        NodeType = DWH_NODE_TYPE,\n",
    "        NumberofNodes = int(DWH_NUM_NODES),\n",
    "\n",
    "        # identifiers and credentials\n",
    "        DBName = DWH_DB,\n",
    "        ClusterIdentifier = DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername = DWH_DB_USER,\n",
    "        MasterUserPassword = DWH_DB_PASSWORD,\n",
    "\n",
    "        # roles (for s3 access)\n",
    "        IamRoles = [roleArn]\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the cluster to see its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    keysToShow = ['ClusterIdentifier', 'NodeType', 'ClusterStatus', 'MasterUsername', 'DBName', 'Endpoint', 'NumberOfNodes', 'VpcId']\n",
    "    x = [(k,v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x columns=['key', 'value'])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(\n",
    "    ClusterIdentifier = DWH_CLUSTER_IDENTIFIER\n",
    ")['Clusters'][0]\n",
    "\n",
    "\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "\n",
    "print(f'DWH_ENDPOINT : {DWH_ENDPOINT}')\n",
    "print(f'DWH_ROLE_ARN : {DWH_ROLE_ARN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open an Incoming TCP port to access the cluster endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id = myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName = defaultSg.group_name,\n",
    "        CidrIp = '0.0.0.0/0',\n",
    "        IpProtocol = 'TCP',\n",
    "        FromPort = int(DWH_PORT),\n",
    "        ToPort = int(DWH_PORT)\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = \"postgresql://{}:{}@{}:{}/{}\".format(\n",
    "    DWH_DB_USER,\n",
    "    DWH_DB_PASSWORD,\n",
    "    DWH_ENDPOINT,\n",
    "    DWH_PORT,\n",
    "    DWH_DB\n",
    ")\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM artists limit 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM time limit 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM songs limit 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM songplays order by songplay_id limit 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from staging_events;\n",
    "delete from staging_songs;\n",
    "delete from songplays;\n",
    "delete from users;\n",
    "delete from songs;\n",
    "delete from artists;\n",
    "delete from time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)\n",
    "#### CAREFUL!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aws': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d06b89363d0a8b4b6ce9f52c643f5341f4010b8ebef937b4523cde8a8895ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
